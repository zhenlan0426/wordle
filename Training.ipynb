{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a2d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_pt import *\n",
    "import pickle\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c359764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "dropout = 0.1\n",
    "multiple_factor = 1\n",
    "layers = 2\n",
    "batch_size = 64\n",
    "agg = 'mean' # mean,sum,min,max\n",
    "lr = 1e-4\n",
    "clip = 1\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45745666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b576db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ys = np.load('ys.npy')\n",
    "weights = np.load('weights.npy')\n",
    "length = np.load('length.npy')\n",
    "words_embed = np.load('possible_words_embed.npy')\n",
    "with open('indexes.pkl', 'rb') as f:\n",
    "    indexes = pickle.load( f)\n",
    "\n",
    "# train/val split\n",
    "np.random.seed(0)\n",
    "train_idx = np.random.rand(ys.shape[0])>0.2\n",
    "val_idx = np.logical_not(train_idx)\n",
    "\n",
    "ys_train, ys_val = ys[train_idx], ys[val_idx]\n",
    "weights_train, weights_val = weights[train_idx], weights[val_idx]\n",
    "length_train, length_val = length[train_idx], length[val_idx]\n",
    "indexes_train = [idx for idx,bol in zip(indexes,train_idx) if bol]\n",
    "indexes_val = [idx for idx,bol in zip(indexes,train_idx) if not bol]\n",
    "\n",
    "# set up dataloader\n",
    "dataset_train = CustomDataset(ys_train,length_train,indexes_train,words_embed)\n",
    "sampler = WeightedRandomSampler(weights_train, 50000)\n",
    "dataset_train = DataLoader(dataset_train, batch_size=batch_size, sampler=sampler,collate_fn=collate)\n",
    "\n",
    "dataset_val = CustomDataset(ys_val,length_val,indexes_val,words_embed)\n",
    "sampler = WeightedRandomSampler(weights_val, 10000)\n",
    "dataset_val = DataLoader(dataset_val, batch_size=batch_size, sampler=sampler,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580a586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b8612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pointNet(layers,embed_size,agg,dropout,multiple_factor).to('cuda')\n",
    "opt = Adam([    {'params': [p for p in model.parameters() if p is not model.w]},\\\n",
    "                {'params': model.w, 'lr': lr/4}\n",
    "            ],lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc4b1341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: +1.361, val_loss: +0.659 \n",
      "\n",
      "epoch:1, train_loss: +1.005, val_loss: +0.587 \n",
      "\n",
      "epoch:2, train_loss: +0.737, val_loss: +0.448 \n",
      "\n",
      "epoch:3, train_loss: +0.535, val_loss: +0.323 \n",
      "\n",
      "epoch:4, train_loss: +0.385, val_loss: +0.208 \n",
      "\n",
      "epoch:5, train_loss: +0.279, val_loss: +0.172 \n",
      "\n",
      "epoch:6, train_loss: +0.204, val_loss: +0.108 \n",
      "\n",
      "epoch:7, train_loss: +0.148, val_loss: +0.083 \n",
      "\n",
      "epoch:8, train_loss: +0.104, val_loss: +0.077 \n",
      "\n",
      "epoch:9, train_loss: +0.069, val_loss: +0.035 \n",
      "\n",
      "Training completed in 159.48054599761963s\n"
     ]
    }
   ],
   "source": [
    "model = train(opt,model,epochs,dataset_train,dataset_val,model.parameters(),clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764ccd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b3b5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = dataset_val.dataset.words_embed\n",
    "l = torch.tensor([2309.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c5fdb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83420/3274103529.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model((torch.tensor(w).to('cuda'),torch.tensor(l).to('cuda')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.7551], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model((torch.tensor(w).to('cuda'),torch.tensor(l).to('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4762b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
