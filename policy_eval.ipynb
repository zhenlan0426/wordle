{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4365dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from torch.optim import Adam\n",
    "from functions_pt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d034f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "dropout = 0.1\n",
    "multiple_factor = 1\n",
    "layers = 2\n",
    "batch_size = 64\n",
    "agg = 'mean' # mean,sum,min,max\n",
    "model = pointNet(layers,embed_size,agg,dropout,multiple_factor)#.to('cuda')\n",
    "#model.load_state_dict(torch.load('baseline_noBN.pt'))\n",
    "#model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a04240",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embed = np.load('possible_words_embed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c47ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90f48605",
   "metadata": {},
   "source": [
    "RL Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96523eb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0, score:3.7167605023819843\n",
      "set size:410\n",
      "loss:0.7993103265762329\n",
      "loss:0.6610571146011353\n",
      "loss:0.537652850151062\n",
      "iter:1, score:3.6383715894326554\n",
      "set size:773\n",
      "loss:0.37487322092056274\n",
      "loss:0.3575732409954071\n",
      "loss:0.42171216011047363\n",
      "iter:2, score:3.6245127760935483\n",
      "set size:1110\n",
      "loss:0.1301199495792389\n",
      "loss:0.1377747803926468\n",
      "loss:0.2738572657108307\n",
      "iter:3, score:3.5201385881333924\n",
      "set size:1392\n",
      "loss:0.10861077159643173\n",
      "loss:0.262614905834198\n",
      "loss:0.2393147498369217\n",
      "iter:4, score:3.541359896058901\n",
      "set size:1661\n",
      "loss:0.28312626481056213\n",
      "loss:0.13119876384735107\n",
      "loss:0.2226516157388687\n",
      "iter:5, score:3.521870939800779\n",
      "set size:1927\n",
      "loss:0.16784915328025818\n",
      "loss:0.08862055838108063\n",
      "loss:0.17878347635269165\n",
      "iter:6, score:3.5495885664789983\n",
      "set size:2206\n",
      "loss:0.12500956654548645\n",
      "loss:0.16198591887950897\n",
      "loss:0.2519560158252716\n",
      "iter:7, score:3.505413598960588\n",
      "set size:2483\n",
      "loss:0.07312078773975372\n",
      "loss:0.1162087544798851\n",
      "loss:0.13688907027244568\n",
      "iter:8, score:3.5313988739714173\n",
      "set size:2667\n",
      "loss:0.07127027213573456\n",
      "loss:0.05711156874895096\n",
      "loss:0.11357668787240982\n",
      "iter:9, score:3.5045474231268945\n",
      "set size:2926\n",
      "loss:0.0513969324529171\n",
      "loss:0.16823995113372803\n",
      "loss:0.1204567551612854\n",
      "iter:10, score:3.484192291035083\n",
      "set size:3191\n",
      "loss:0.04741863161325455\n",
      "loss:0.09874986112117767\n",
      "loss:0.10511284321546555\n",
      "iter:11, score:3.4984841922910372\n",
      "set size:3445\n",
      "loss:0.10020130127668381\n",
      "loss:0.04790566489100456\n",
      "loss:0.14099450409412384\n",
      "iter:12, score:3.48419229103508\n",
      "set size:3699\n",
      "loss:0.05152396857738495\n",
      "loss:0.039115749299526215\n",
      "loss:0.14090724289417267\n",
      "iter:13, score:3.4495452576873116\n",
      "set size:3948\n",
      "loss:0.09399386495351791\n",
      "loss:0.04443484917283058\n",
      "loss:0.04514116793870926\n",
      "iter:14, score:3.499350368124731\n",
      "set size:4126\n",
      "loss:0.13370175659656525\n",
      "loss:0.09021074324846268\n",
      "loss:0.04334932565689087\n",
      "iter:15, score:3.492854049372025\n",
      "set size:4374\n",
      "loss:0.0827670693397522\n",
      "loss:0.03337514027953148\n",
      "loss:0.08697312325239182\n",
      "iter:16, score:3.46773495019489\n",
      "set size:4610\n",
      "loss:0.12378198653459549\n",
      "loss:0.07694309949874878\n",
      "loss:0.03906109556555748\n",
      "iter:17, score:3.474231268947599\n",
      "set size:4850\n",
      "loss:0.03412960469722748\n",
      "loss:0.12670627236366272\n",
      "loss:0.08142374455928802\n",
      "iter:18, score:3.4439151147683007\n",
      "set size:5018\n",
      "loss:0.08124088495969772\n",
      "loss:0.1209821105003357\n",
      "loss:0.04386214166879654\n",
      "iter:19, score:3.4499783456041597\n",
      "set size:5260\n",
      "loss:0.12305966019630432\n",
      "loss:0.07449668645858765\n",
      "loss:0.07155179232358932\n",
      "iter:20, score:3.4807275877003065\n",
      "set size:5505\n",
      "loss:0.04255043715238571\n",
      "loss:0.11609859764575958\n",
      "loss:0.12790313363075256\n",
      "iter:21, score:3.5041143352100503\n",
      "set size:5732\n",
      "loss:0.07582172006368637\n",
      "loss:0.07613062113523483\n",
      "loss:0.08356159925460815\n",
      "iter:22, score:3.4642702468601128\n",
      "set size:5831\n",
      "loss:0.1316903531551361\n",
      "loss:0.043226033449172974\n",
      "loss:0.11964298039674759\n",
      "iter:23, score:3.502381983542662\n",
      "set size:6070\n",
      "loss:0.08597523719072342\n",
      "loss:0.0428476557135582\n",
      "loss:0.032058972865343094\n",
      "iter:24, score:3.4421827631009103\n",
      "set size:6192\n",
      "loss:0.029990660026669502\n",
      "loss:0.1250758022069931\n",
      "loss:0.03406798467040062\n",
      "iter:25, score:3.471199653529668\n",
      "set size:6395\n",
      "loss:0.04132528603076935\n",
      "loss:0.033595990389585495\n",
      "loss:0.07275833934545517\n",
      "iter:26, score:3.471199653529668\n",
      "set size:6463\n",
      "loss:0.11286885291337967\n",
      "loss:0.11110160499811172\n",
      "loss:0.08197615295648575\n",
      "iter:27, score:3.44261585101776\n",
      "set size:6660\n",
      "loss:0.12823587656021118\n",
      "loss:0.07477713376283646\n",
      "loss:0.1290593445301056\n",
      "iter:28, score:3.475963620614989\n",
      "set size:6750\n",
      "loss:0.03845138102769852\n",
      "loss:0.08537118881940842\n",
      "loss:0.0803716704249382\n",
      "iter:29, score:3.4755305326981385\n",
      "set size:6907\n",
      "loss:0.12292413413524628\n",
      "loss:0.03807664290070534\n",
      "loss:0.08537594228982925\n"
     ]
    }
   ],
   "source": [
    "# model trained from start\n",
    "lr = 6e-5\n",
    "clip = 0.03\n",
    "epochs = 3\n",
    "damp = 1\n",
    "iterations = 30\n",
    "max_data = 2000\n",
    "states = set()\n",
    "opt = Adam(model.parameters(),betas=(0.85, 0.95),lr=lr)\n",
    "for i in range(iterations):\n",
    "    # policy evaluation\n",
    "    model.eval()\n",
    "    score = evaluate_save(matrix,np.arange(2309),policy_model,2309,0,model=model,words_embed=words_embed,top=0.6,\n",
    "                         eps=0.09/(i+1))\n",
    "    print('iter:{}, score:{}'.format(i,score))\n",
    "    \n",
    "    # prepare data for training\n",
    "    index,val,log_prob = zip(*out)\n",
    "    for element in index:\n",
    "        states.add(tuple(element))\n",
    "    print('set size:{}'.format(len(states)))\n",
    "    prob = np.array(log_prob)\n",
    "    prob -= prob.mean()\n",
    "    prob = np.exp(prob/damp)\n",
    "    prob = torch.tensor(prob,dtype=torch.float32,device='cuda')\n",
    "    length = torch.tensor([len(i) for i in index],dtype=torch.float32,device='cuda')\n",
    "    words = torch.tensor(words_embed[np.concatenate(index)]).long().to('cuda')\n",
    "    ys = torch.tensor(val,dtype=torch.float32,device='cuda')\n",
    "\n",
    "    \n",
    "    # policy update\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        yhat = model((words,length))\n",
    "        loss = torch.sum(prob*(ys-yhat)**2)/torch.sum(prob)\n",
    "        loss.backward()\n",
    "        print('loss:{}'.format(loss.item()))\n",
    "        clip_grad_value_(model.parameters(),clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    #print(model.w)\n",
    "    while len(out)>max_data:\n",
    "        out.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58899cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'RL0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c9a72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.437418796015592"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6,\n",
    "                         eps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6dc8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8bd7aae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0, score:3.5595495885664814\n",
      "set size:400\n",
      "loss:0.7726379632949829\n",
      "loss:0.7377428412437439\n",
      "loss:0.6685836315155029\n",
      "iter:1, score:3.5188393243828506\n",
      "set size:733\n",
      "loss:0.49167317152023315\n",
      "loss:0.374877393245697\n",
      "loss:0.2742391526699066\n",
      "iter:2, score:3.4876569943698588\n",
      "set size:1034\n",
      "loss:0.19567330181598663\n",
      "loss:0.1443445384502411\n",
      "loss:0.08508361130952835\n",
      "iter:3, score:3.4595062797747964\n",
      "set size:1122\n",
      "loss:0.08880160003900528\n",
      "loss:0.09266699850559235\n",
      "loss:0.21844609081745148\n",
      "iter:4, score:3.49935036812473\n",
      "set size:1400\n",
      "loss:0.12617264688014984\n",
      "loss:0.11462590098381042\n",
      "loss:0.10650429129600525\n",
      "iter:5, score:3.4512776093547\n",
      "set size:1473\n",
      "loss:0.0920286774635315\n",
      "loss:0.16089190542697906\n",
      "loss:0.07193559408187866\n",
      "iter:6, score:3.4491121697704634\n",
      "set size:1523\n",
      "loss:0.06548918038606644\n",
      "loss:0.060486335307359695\n",
      "loss:0.10920626670122147\n",
      "iter:7, score:3.4564746643568647\n",
      "set size:1579\n",
      "loss:0.15068767964839935\n",
      "loss:0.06904400885105133\n",
      "loss:0.116324283182621\n",
      "iter:8, score:3.448679081853617\n",
      "set size:1599\n",
      "loss:0.054545316845178604\n",
      "loss:0.06332392245531082\n",
      "loss:0.10069689899682999\n",
      "iter:9, score:3.443048938934604\n",
      "set size:1612\n",
      "loss:0.1750544309616089\n",
      "loss:0.08510209619998932\n",
      "loss:0.04109570384025574\n",
      "iter:10, score:3.4577739281074065\n",
      "set size:1639\n",
      "loss:0.04019847884774208\n",
      "loss:0.13449059426784515\n",
      "loss:0.12595969438552856\n",
      "iter:11, score:3.4486790818536166\n",
      "set size:1654\n",
      "loss:0.05319322645664215\n",
      "loss:0.03659055382013321\n",
      "loss:0.08174363523721695\n",
      "iter:12, score:3.4426158510177567\n",
      "set size:1664\n",
      "loss:0.04639320820569992\n",
      "loss:0.11782637983560562\n",
      "loss:0.0782160684466362\n",
      "iter:13, score:3.449545257687311\n",
      "set size:1684\n",
      "loss:0.11522673070430756\n",
      "loss:0.08186986297369003\n",
      "loss:0.037496261298656464\n",
      "iter:14, score:3.437851883932439\n",
      "set size:1704\n",
      "loss:0.08541642874479294\n",
      "loss:0.036573395133018494\n",
      "loss:0.0398641861975193\n",
      "iter:15, score:3.4452143785188407\n",
      "set size:1718\n",
      "loss:0.07293616235256195\n",
      "loss:0.03288283944129944\n",
      "loss:0.03567681089043617\n",
      "iter:16, score:3.4439151147682985\n",
      "set size:1727\n",
      "loss:0.1544712334871292\n",
      "loss:0.11897793412208557\n",
      "loss:0.12234923243522644\n",
      "iter:17, score:3.448679081853617\n",
      "set size:1739\n",
      "loss:0.07377196103334427\n",
      "loss:0.15980330109596252\n",
      "loss:0.07425421476364136\n",
      "iter:18, score:3.452576873105242\n",
      "set size:1801\n",
      "loss:0.03663899749517441\n",
      "loss:0.15861158072948456\n",
      "loss:0.1919044405221939\n",
      "iter:19, score:3.4599393676916432\n",
      "set size:1840\n",
      "loss:0.03957498446106911\n",
      "loss:0.0322011336684227\n",
      "loss:0.034468214958906174\n",
      "iter:20, score:3.4512776093547006\n",
      "set size:1857\n",
      "loss:0.07211904227733612\n",
      "loss:0.0744406208395958\n",
      "loss:0.0344855822622776\n",
      "iter:21, score:3.4426158510177585\n",
      "set size:1866\n",
      "loss:0.03712921962141991\n",
      "loss:0.030993182212114334\n",
      "loss:0.045523256063461304\n",
      "iter:22, score:3.4473798181030766\n",
      "set size:2076\n",
      "loss:0.11121257394552231\n",
      "loss:0.07887089252471924\n",
      "loss:0.0740630179643631\n",
      "iter:23, score:3.436985708098746\n",
      "set size:2082\n",
      "loss:0.0721924751996994\n",
      "loss:0.07238630205392838\n",
      "loss:0.1514415442943573\n",
      "iter:24, score:3.4499783456041593\n",
      "set size:2108\n",
      "loss:0.03665146976709366\n",
      "loss:0.10726770758628845\n",
      "loss:0.07471262663602829\n",
      "iter:25, score:3.4460805543525352\n",
      "set size:2121\n",
      "loss:0.1504138708114624\n",
      "loss:0.06905433535575867\n",
      "loss:0.04670875892043114\n",
      "iter:26, score:3.43482026851451\n",
      "set size:2124\n",
      "loss:0.07848610728979111\n",
      "loss:0.0342746376991272\n",
      "loss:0.04027188569307327\n",
      "iter:27, score:3.470766565612821\n",
      "set size:2397\n",
      "loss:0.07175122201442719\n",
      "loss:0.14335696399211884\n",
      "loss:0.041419051587581635\n",
      "iter:28, score:3.4794283239497608\n",
      "set size:2647\n",
      "loss:0.11360727250576019\n",
      "loss:0.031611863523721695\n",
      "loss:0.06818348169326782\n",
      "iter:29, score:3.4772628843655267\n",
      "set size:2672\n",
      "loss:0.07559149712324142\n",
      "loss:0.034134719520807266\n",
      "loss:0.03629569336771965\n"
     ]
    }
   ],
   "source": [
    "# model trained from start\n",
    "# eps greedy\n",
    "lr = 6e-5\n",
    "clip = 0.03\n",
    "epochs = 3\n",
    "damp = 1\n",
    "iterations = 30\n",
    "max_data = 2000\n",
    "states = set()\n",
    "opt = Adam(model.parameters(),betas=(0.85, 0.95),lr=lr)\n",
    "for i in range(iterations):\n",
    "    # policy evaluation\n",
    "    model.eval()\n",
    "    score = evaluate_save(matrix,np.arange(2309),policy_model_eps,2309,0,model=model,words_embed=words_embed,top=0.6,\n",
    "                         eps=0.25/(i+1)**(0.5))\n",
    "    print('iter:{}, score:{}'.format(i,score))\n",
    "    \n",
    "    # prepare data for training\n",
    "    index,val,log_prob = zip(*out)\n",
    "    for element in index:\n",
    "        states.add(tuple(element))\n",
    "    print('set size:{}'.format(len(states)))\n",
    "    prob = np.array(log_prob)\n",
    "    prob -= prob.mean()\n",
    "    prob = np.exp(prob/damp)\n",
    "    prob = torch.tensor(prob,dtype=torch.float32,device='cuda')\n",
    "    length = torch.tensor([len(i) for i in index],dtype=torch.float32,device='cuda')\n",
    "    words = torch.tensor(words_embed[np.concatenate(index)]).long().to('cuda')\n",
    "    ys = torch.tensor(val,dtype=torch.float32,device='cuda')\n",
    "\n",
    "    \n",
    "    # policy update\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        yhat = model((words,length))\n",
    "        loss = torch.sum(prob*(ys-yhat)**2)/torch.sum(prob)\n",
    "        loss.backward()\n",
    "        print('loss:{}'.format(loss.item()))\n",
    "        clip_grad_value_(model.parameters(),clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    #print(model.w)\n",
    "    while len(out)>max_data:\n",
    "        out.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7778b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'RL_eps.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a39a7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5889995669120847"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(matrix,np.arange(2309),policy_model_eps,2309,model=model,words_embed=words_embed,top=0.6,\n",
    "                         eps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844a20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d35d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7068909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b10800",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = -1\n",
    "for k,v in mapping.items():\n",
    "    if v>max_:\n",
    "        k_max = k\n",
    "        max_ = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956d4635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1029411764705874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(matrix[:,np.array(k_max)],np.array(k_max),policy_lookup,len(k_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6730a285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1029411764705874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438980ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f14a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1249999999999987"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly worse than # of steps required by mapping as expected\n",
    "evaluate(matrix[:,np.array(k_max)],np.array(k_max),policy_model,len(k_max),model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035a930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48ab034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:0.0, steps:3.465569510610656\n",
      "factor:0.5, steps:3.4638371589432673\n",
      "factor:1.0, steps:3.4634040710264204\n",
      "factor:1.5, steps:3.4634040710264204\n",
      "factor:2.0, steps:3.4634040710264204\n",
      "factor:2.5, steps:3.462970983109573\n",
      "factor:3.0, steps:3.4638371589432673\n",
      "factor:3.5, steps:3.4642702468601136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# entropy_best policy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy_entropy_best\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, steps:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i,steps))\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:106\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(matrix, index, policy, count, **kways)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# guess_row += p * 0\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     tmp2 \u001b[38;5;241m=\u001b[39m tmp \u001b[38;5;241m==\u001b[39m u\n\u001b[0;32m--> 106\u001b[0m     guess_row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m guess_row\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:92\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(matrix, index, policy, count, **kways)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# best = np.log2(count)\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m tmp \u001b[38;5;241m=\u001b[39m matrix[row]\n\u001b[1;32m     95\u001b[0m unq,counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(tmp,return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:251\u001b[0m, in \u001b[0;36mpolicy_entropy_best\u001b[0;34m(matrix, index, factor)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m12953\u001b[39m):\n\u001b[1;32m    250\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m matrix[row]\n\u001b[0;32m--> 251\u001b[0m     unq,counts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     ps \u001b[38;5;241m=\u001b[39m counts\u001b[38;5;241m/\u001b[39mcount\n\u001b[1;32m    253\u001b[0m     entro \u001b[38;5;241m=\u001b[39m entropy(ps)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    270\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py:360\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_counts:\n\u001b[1;32m    359\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(np\u001b[38;5;241m.\u001b[39mnonzero(mask) \u001b[38;5;241m+\u001b[39m ([mask\u001b[38;5;241m.\u001b[39msize],))\n\u001b[0;32m--> 360\u001b[0m     ret \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m,)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/lib/function_base.py:1261\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(a, n, axis, prepend, append)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff requires input that is at least one dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1259\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, nd)\n\u001b[0;32m-> 1261\u001b[0m combined \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prepend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   1263\u001b[0m     prepend \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(prepend)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# entropy_best policy\n",
    "    steps = evaluate(matrix,np.arange(2309),policy_entropy_best,2309,factor=i)\n",
    "    print('factor:{}, steps:{}'.format(i,steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615e4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9693ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:0.0, steps:3.5275010827197937\n",
      "factor:0.5, steps:3.4638371589432673\n",
      "factor:1.0, steps:3.4634040710264204\n",
      "factor:1.5, steps:3.4634040710264204\n",
      "factor:2.0, steps:3.4634040710264204\n",
      "factor:2.5, steps:3.462970983109573\n",
      "factor:3.0, steps:3.4638371589432673\n",
      "factor:3.5, steps:3.4642702468601136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# entropy policy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy_entropy\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, steps:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i,steps))\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:100\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(matrix, index, policy, count, **kways)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# guess_row += p * 0\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     tmp2 \u001b[38;5;241m=\u001b[39m tmp \u001b[38;5;241m==\u001b[39m u\n\u001b[0;32m--> 100\u001b[0m     guess_row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m guess_row\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:86\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(matrix, index, policy, count, **kways)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# best = np.log2(count)\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m tmp \u001b[38;5;241m=\u001b[39m matrix[row]\n\u001b[1;32m     89\u001b[0m unq,counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(tmp,return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:165\u001b[0m, in \u001b[0;36mpolicy_entropy\u001b[0;34m(matrix, index, factor)\u001b[0m\n\u001b[1;32m    163\u001b[0m ps \u001b[38;5;241m=\u001b[39m counts\u001b[38;5;241m/\u001b[39mcount\n\u001b[1;32m    164\u001b[0m entro \u001b[38;5;241m=\u001b[39m entropy(ps)\n\u001b[0;32m--> 165\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43munq\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m242\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    167\u001b[0m     entro \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prob[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m factor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# entropy policy\n",
    "for i in np.linspace(0,7,15):\n",
    "    steps = evaluate(matrix,np.arange(2309),policy_entropy,2309,factor=i)\n",
    "    print('factor:{}, steps:{}'.format(i,steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56d63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1f55ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:1.0, steps:3.4634040710264204\n",
      "factor:1.25, steps:3.462970983109573\n",
      "factor:1.5, steps:3.4638371589432673\n",
      "factor:1.75, steps:3.4642702468601136\n",
      "factor:2.0, steps:3.4655695106106554\n"
     ]
    }
   ],
   "source": [
    "# entropy policy with depth info\n",
    "for i in np.linspace(1,2,5):\n",
    "    steps = evaluate_depth(matrix,np.arange(2309),policy_entropy_depth,2309,factor=i,depth=1)\n",
    "    print('factor:{}, steps:{}'.format(i,steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbe1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c17dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ba82ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5266349068860987"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how well model does on full problem that it is not trained on\n",
    "#     if count == 1: return 1\n",
    "#     if count == 2: return 1.5\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae855e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8778692074491117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if entro == best:return row\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4707b1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6223473365093115"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                 if c == 1:\n",
    "#                     continue\n",
    "#                 if c == 2:\n",
    "#                     value += p\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4439de6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.558683412732789"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old policy_model\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde664ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7756604590731935"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new policy_model\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5cfc336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.873538328280638"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new + if entro==best: return row\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c06c561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5240363793850142"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new policy_model +\n",
    "#                 if c == 1:\n",
    "#                     continue\n",
    "#                 if c == 2:\n",
    "#                     value += p\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991687a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d1aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6bc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0954569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
