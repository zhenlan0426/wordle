{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4365dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcbb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = -1\n",
    "for k,v in mapping.items():\n",
    "    if v>max_:\n",
    "        k_max = k\n",
    "        max_ = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a715e6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1029411764705874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(matrix[:,np.array(k_max)],np.array(k_max),policy_lookup,len(k_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6049ecbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1029411764705874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23926774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af54247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_pt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d034f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "dropout = 0.1\n",
    "multiple_factor = 1\n",
    "layers = 2\n",
    "batch_size = 64\n",
    "agg = 'mean' # mean,sum,min,max\n",
    "model = pointNet(layers,embed_size,agg,dropout,multiple_factor)#.to('cuda')\n",
    "model.load_state_dict(torch.load('baseline_noBN.pt'))\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a04240",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embed = np.load('possible_words_embed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043844d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9a72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f14a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1249999999999987"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly worse than # of steps required by mapping as expected\n",
    "evaluate(matrix[:,np.array(k_max)],np.array(k_max),policy_model,len(k_max),model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1671002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c1fa09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:0.0, steps:3.5275010827197937\n",
      "factor:0.5, steps:3.4638371589432673\n",
      "factor:1.0, steps:3.4634040710264204\n",
      "factor:1.5, steps:3.4634040710264204\n",
      "factor:2.0, steps:3.4634040710264204\n",
      "factor:2.5, steps:3.462970983109573\n",
      "factor:3.0, steps:3.4638371589432673\n",
      "factor:3.5, steps:3.4642702468601136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# entropy policy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy_entropy\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, steps:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i,steps))\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:100\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(matrix, index, policy, count, **kways)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# guess_row += p * 0\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     tmp2 \u001b[38;5;241m=\u001b[39m tmp \u001b[38;5;241m==\u001b[39m u\n\u001b[0;32m--> 100\u001b[0m     guess_row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m guess_row\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:86\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(matrix, index, policy, count, **kways)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# best = np.log2(count)\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m tmp \u001b[38;5;241m=\u001b[39m matrix[row]\n\u001b[1;32m     89\u001b[0m unq,counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(tmp,return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:165\u001b[0m, in \u001b[0;36mpolicy_entropy\u001b[0;34m(matrix, index, factor)\u001b[0m\n\u001b[1;32m    163\u001b[0m ps \u001b[38;5;241m=\u001b[39m counts\u001b[38;5;241m/\u001b[39mcount\n\u001b[1;32m    164\u001b[0m entro \u001b[38;5;241m=\u001b[39m entropy(ps)\n\u001b[0;32m--> 165\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43munq\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m242\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    167\u001b[0m     entro \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prob[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m factor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# entropy policy\n",
    "for i in np.linspace(0,7,15):\n",
    "    steps = evaluate(matrix,np.arange(2309),policy_entropy,2309,factor=i)\n",
    "    print('factor:{}, steps:{}'.format(i,steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95eb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1c5a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:1.0, steps:3.4634040710264204\n",
      "factor:1.25, steps:3.462970983109573\n",
      "factor:1.5, steps:3.4638371589432673\n",
      "factor:1.75, steps:3.4642702468601136\n",
      "factor:2.0, steps:3.4655695106106554\n"
     ]
    }
   ],
   "source": [
    "# entropy policy with depth info\n",
    "for i in np.linspace(1,2,5):\n",
    "    steps = evaluate_depth(matrix,np.arange(2309),policy_entropy_depth,2309,factor=i,depth=1)\n",
    "    print('factor:{}, steps:{}'.format(i,steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892f98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef9d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ba82ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5266349068860987"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how well model does on full problem that it is not trained on\n",
    "#     if count == 1: return 1\n",
    "#     if count == 2: return 1.5\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1dff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d4477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2741e524",
   "metadata": {},
   "source": [
    "RL Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8127f1a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0, score:3.664356864443484\n",
      "iter:1, score:3.5478562148116075\n",
      "iter:2, score:3.5279341706366414\n",
      "iter:3, score:3.5071459506279794\n",
      "iter:4, score:3.516673884798616\n",
      "iter:5, score:3.515807708964922\n",
      "iter:6, score:3.514075357297534\n",
      "iter:7, score:3.5153746210480747\n",
      "iter:8, score:3.518839324382852\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# policy evaluation\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 11\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwords_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwords_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, score:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i,score))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# prepare data for training\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:145\u001b[0m, in \u001b[0;36mevaluate_save\u001b[0;34m(matrix, index, policy, count, log_p, **kways)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# guess_row += p * 0\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     tmp2 \u001b[38;5;241m=\u001b[39m tmp \u001b[38;5;241m==\u001b[39m u\n\u001b[0;32m--> 145\u001b[0m     guess_row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m \u001b[43mevaluate_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlog_p\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m out\u001b[38;5;241m.\u001b[39mappend((index,guess_row\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,log_p))\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m guess_row\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:145\u001b[0m, in \u001b[0;36mevaluate_save\u001b[0;34m(matrix, index, policy, count, log_p, **kways)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# guess_row += p * 0\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     tmp2 \u001b[38;5;241m=\u001b[39m tmp \u001b[38;5;241m==\u001b[39m u\n\u001b[0;32m--> 145\u001b[0m     guess_row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m \u001b[43mevaluate_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlog_p\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m out\u001b[38;5;241m.\u001b[39mappend((index,guess_row\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,log_p))\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m guess_row\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:135\u001b[0m, in \u001b[0;36mevaluate_save\u001b[0;34m(matrix, index, policy, count, log_p, **kways)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# best = np.log2(count)\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m tmp \u001b[38;5;241m=\u001b[39m matrix[row]\n\u001b[1;32m    138\u001b[0m unq,counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(tmp,return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:286\u001b[0m, in \u001b[0;36mpolicy_model\u001b[0;34m(matrix, index, model, words_embed, top, eps)\u001b[0m\n\u001b[1;32m    284\u001b[0m word \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(words_embed[np\u001b[38;5;241m.\u001b[39mconcatenate(index_)],device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 286\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    288\u001b[0m value \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39marray(p_),out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions_pt.py:106\u001b[0m, in \u001b[0;36mpointNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(words)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmainNN:\n\u001b[0;32m--> 106\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseg2all\u001b[49m\u001b[43m,\u001b[49m\u001b[43mall2seg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_linear(segment_csr(out,all2seg,reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg))\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#out = torch.maximum(self.min_,out.squeeze() + self.w * torch.log2(length))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions_pt.py:80\u001b[0m, in \u001b[0;36mpointNet_block.forward\u001b[0;34m(self, in_, seg2all, all2seg)\u001b[0m\n\u001b[1;32m     78\u001b[0m out_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_update(out_group)\n\u001b[1;32m     79\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([out,out_group[seg2all]],\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39min_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/activation.py:772\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_slope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1631\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(leaky_relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, negative_slope\u001b[38;5;241m=\u001b[39mnegative_slope, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 1631\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_slope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28minput\u001b[39m, negative_slope)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 6e-5\n",
    "clip = 1\n",
    "epochs = 2\n",
    "damp = 1\n",
    "iterations = 15\n",
    "max_data = 2000\n",
    "\n",
    "for i in range(iterations):\n",
    "    # policy evaluation\n",
    "    model.eval()\n",
    "    score = evaluate_save(matrix,np.arange(2309),policy_model,2309,0,model=model,words_embed=words_embed,top=0.6,\n",
    "                         eps=0.2/(i+1)**2)\n",
    "    print('iter:{}, score:{}'.format(i,score))\n",
    "    \n",
    "    # prepare data for training\n",
    "    index,val,log_prob = zip(*out)\n",
    "    prob = np.array(log_prob)\n",
    "    prob -= prob.mean()\n",
    "    prob = np.exp(prob/damp)\n",
    "    prob = torch.tensor(prob,dtype=torch.float32,device='cuda')\n",
    "    length = torch.tensor([len(i) for i in index],dtype=torch.float32,device='cuda')\n",
    "    words = torch.tensor(words_embed[np.concatenate(index)]).long().to('cuda')\n",
    "    ys = torch.tensor(val,dtype=torch.float32,device='cuda')\n",
    "\n",
    "    \n",
    "    # policy update\n",
    "    model.train()\n",
    "    opt = Adam([    {'params': [p for p in model.parameters() if p is not model.w]},\\\n",
    "                {'params': model.w, 'lr': lr/4}\n",
    "            ],lr=lr)\n",
    "    for _ in range(epochs):\n",
    "        yhat = model((words,length))\n",
    "        loss = torch.mean(prob*(ys-yhat)**2)\n",
    "        loss.backward()\n",
    "        clip_grad_value_(model.parameters(),clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    #print(model.w)\n",
    "    while len(out)>max_data:\n",
    "        out.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc59495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15d19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f148282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0, score:3.71892594196622\n",
      "set size:398\n",
      "loss\n",
      "0 0.12590913474559784\n",
      "loss\n",
      "1 0.10894769430160522\n",
      "iter:1, score:3.542226071892596\n",
      "set size:715\n",
      "loss\n",
      "0 0.14993155002593994\n",
      "loss\n",
      "1 0.1562322974205017\n",
      "iter:2, score:3.5179731485491574\n",
      "set size:881\n",
      "loss\n",
      "0 0.177512064576149\n",
      "loss\n",
      "1 0.17453089356422424\n",
      "iter:3, score:3.518406236466005\n",
      "set size:994\n",
      "loss\n",
      "0 0.1868080198764801\n",
      "loss\n",
      "1 0.1805325299501419\n",
      "iter:4, score:3.514075357297534\n",
      "set size:1049\n",
      "loss\n",
      "0 0.1912974864244461\n",
      "loss\n",
      "1 0.19184242188930511\n",
      "iter:5, score:3.515807708964922\n",
      "set size:1052\n",
      "loss\n",
      "0 0.1924106776714325\n",
      "loss\n",
      "1 0.19461648166179657\n",
      "iter:6, score:3.513209181463839\n",
      "set size:1052\n",
      "loss\n",
      "0 0.19937260448932648\n",
      "loss\n",
      "1 0.19698752462863922\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# policy evaluation\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 11\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwords_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwords_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, score:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i,score))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# prepare data for training\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:145\u001b[0m, in \u001b[0;36mevaluate_save\u001b[0;34m(matrix, index, policy, count, log_p, **kways)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# guess_row += p * 0\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     tmp2 \u001b[38;5;241m=\u001b[39m tmp \u001b[38;5;241m==\u001b[39m u\n\u001b[0;32m--> 145\u001b[0m     guess_row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m \u001b[43mevaluate_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlog_p\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m out\u001b[38;5;241m.\u001b[39mappend((index,guess_row\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,log_p))\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m guess_row\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:135\u001b[0m, in \u001b[0;36mevaluate_save\u001b[0;34m(matrix, index, policy, count, log_p, **kways)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# best = np.log2(count)\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m tmp \u001b[38;5;241m=\u001b[39m matrix[row]\n\u001b[1;32m    138\u001b[0m unq,counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(tmp,return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:286\u001b[0m, in \u001b[0;36mpolicy_model\u001b[0;34m(matrix, index, model, words_embed, top, eps)\u001b[0m\n\u001b[1;32m    284\u001b[0m word \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(words_embed[np\u001b[38;5;241m.\u001b[39mconcatenate(index_)],device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 286\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    288\u001b[0m value \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39marray(p_),out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions_pt.py:106\u001b[0m, in \u001b[0;36mpointNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(words)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmainNN:\n\u001b[0;32m--> 106\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseg2all\u001b[49m\u001b[43m,\u001b[49m\u001b[43mall2seg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_linear(segment_csr(out,all2seg,reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg))\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#out = torch.maximum(self.min_,out.squeeze() + self.w * torch.log2(length))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions_pt.py:76\u001b[0m, in \u001b[0;36mpointNet_block.forward\u001b[0;34m(self, in_, seg2all, all2seg)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_,seg2all,all2seg):\n\u001b[0;32m---> 76\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     out_group \u001b[38;5;241m=\u001b[39m segment_csr(out,all2seg,reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg)\n\u001b[1;32m     78\u001b[0m     out_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_update(out_group)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 6e-5\n",
    "clip = 1\n",
    "epochs = 2\n",
    "damp = 1\n",
    "iterations = 15\n",
    "max_data = 2000\n",
    "states = set()\n",
    "for i in range(iterations):\n",
    "    # policy evaluation\n",
    "    model.eval()\n",
    "    score = evaluate_save(matrix,np.arange(2309),policy_model,2309,0,model=model,words_embed=words_embed,top=0.6,\n",
    "                         eps=0.2/(i+1)**2)\n",
    "    print('iter:{}, score:{}'.format(i,score))\n",
    "    \n",
    "    # prepare data for training\n",
    "    index,val,log_prob = zip(*out)\n",
    "    for element in index:\n",
    "        states.add(tuple(element))\n",
    "    print('set size:{}'.format(len(states)))\n",
    "    prob = np.array(log_prob)\n",
    "    prob -= prob.mean()\n",
    "    prob = np.exp(prob/damp)\n",
    "    prob = torch.tensor(prob,dtype=torch.float32,device='cuda')\n",
    "    length = torch.tensor([len(i) for i in index],dtype=torch.float32,device='cuda')\n",
    "    words = torch.tensor(words_embed[np.concatenate(index)]).long().to('cuda')\n",
    "    ys = torch.tensor(val,dtype=torch.float32,device='cuda')\n",
    "\n",
    "    \n",
    "    # policy update\n",
    "    model.train()\n",
    "    opt = Adam([    {'params': [p for p in model.parameters() if p is not model.w]},\\\n",
    "                {'params': model.w, 'lr': lr/4}\n",
    "            ],lr=lr)\n",
    "    for j_ in range(epochs):\n",
    "        yhat = model((words,length))\n",
    "        loss = torch.mean(prob*(ys-yhat)**2)\n",
    "        loss.backward()\n",
    "        print('loss')\n",
    "        print(j_,loss.cpu().item())\n",
    "        clip_grad_value_(model.parameters(),clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    #print(model.w)\n",
    "    while len(out)>max_data:\n",
    "        out.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39aaa09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cfe31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661323d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0, score:3.6860112602858384\n",
      "set size:390\n",
      "loss\n",
      "0 0.1273408979177475\n",
      "iter:1, score:3.5560848852317037\n",
      "set size:728\n",
      "loss\n",
      "0 0.20019201934337616\n",
      "iter:2, score:3.522737115634477\n",
      "set size:888\n",
      "loss\n",
      "0 0.2173539102077484\n",
      "iter:3, score:3.5223040277176283\n",
      "set size:1015\n",
      "loss\n",
      "0 0.2158091962337494\n",
      "iter:4, score:3.515374621048075\n",
      "set size:1059\n",
      "loss\n",
      "0 0.2277476042509079\n",
      "iter:5, score:3.5162407968817693\n",
      "set size:1079\n",
      "loss\n",
      "0 0.21915704011917114\n",
      "iter:6, score:3.512776093546992\n",
      "set size:1096\n",
      "loss\n",
      "0 0.2254505753517151\n",
      "iter:7, score:3.514941533131228\n",
      "set size:1109\n",
      "loss\n",
      "0 0.22602730989456177\n",
      "iter:8, score:3.5140753572975334\n",
      "set size:1122\n",
      "loss\n",
      "0 0.2215365171432495\n",
      "iter:9, score:3.5179731485491574\n",
      "set size:1122\n",
      "loss\n",
      "0 0.2132256031036377\n",
      "iter:10, score:3.514941533131228\n",
      "set size:1122\n",
      "loss\n",
      "0 0.22427460551261902\n",
      "iter:11, score:3.5166738847986165\n",
      "set size:1122\n",
      "loss\n",
      "0 0.21680185198783875\n",
      "iter:12, score:3.512776093546992\n",
      "set size:1123\n",
      "loss\n",
      "0 0.2189253866672516\n",
      "iter:13, score:3.5166738847986165\n",
      "set size:1123\n",
      "loss\n",
      "0 0.21885418891906738\n",
      "iter:14, score:3.5132091814638393\n",
      "set size:1123\n",
      "loss\n",
      "0 0.2211211621761322\n"
     ]
    }
   ],
   "source": [
    "lr = 7e-5\n",
    "clip = 1\n",
    "epochs = 2\n",
    "damp = 1\n",
    "iterations = 15\n",
    "max_data = 0\n",
    "states = set()\n",
    "for i in range(iterations):\n",
    "    # policy evaluation\n",
    "    model.eval()\n",
    "    score = evaluate_save(matrix,np.arange(2309),policy_model,2309,0,model=model,words_embed=words_embed,top=0.6,\n",
    "                         eps=0.2/(i+1))\n",
    "    print('iter:{}, score:{}'.format(i,score))\n",
    "    \n",
    "    # prepare data for training\n",
    "    index,val,log_prob = zip(*out)\n",
    "    for element in index:\n",
    "        states.add(tuple(element))\n",
    "    print('set size:{}'.format(len(states)))\n",
    "    prob = np.array(log_prob)\n",
    "    prob -= prob.mean()\n",
    "    prob = np.exp(prob/damp)\n",
    "    prob = torch.tensor(prob,dtype=torch.float32,device='cuda')\n",
    "    length = torch.tensor([len(i) for i in index],dtype=torch.float32,device='cuda')\n",
    "    words = torch.tensor(words_embed[np.concatenate(index)]).long().to('cuda')\n",
    "    ys = torch.tensor(val,dtype=torch.float32,device='cuda')\n",
    "\n",
    "    \n",
    "    # policy update\n",
    "    model.train()\n",
    "    opt = Adam([    {'params': [p for p in model.parameters() if p is not model.w]},\\\n",
    "                {'params': model.w, 'lr': lr/4}\n",
    "            ],lr=lr)\n",
    "    for j_ in range(epochs):\n",
    "        yhat = model((words,length))\n",
    "        loss = torch.mean(prob*(ys-yhat)**2)\n",
    "        loss.backward()\n",
    "        print('loss')\n",
    "        print(j_,loss.cpu().item())\n",
    "        clip_grad_value_(model.parameters(),clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    #print(model.w)\n",
    "    while len(out)>max_data:\n",
    "        out.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449224b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
