{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4365dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from torch.optim import Adam\n",
    "from functions_pt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d034f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "dropout = 0.1\n",
    "multiple_factor = 1\n",
    "layers = 2\n",
    "batch_size = 64\n",
    "agg = 'mean' # mean,sum,min,max\n",
    "model = pointNet(layers,embed_size,agg,dropout,multiple_factor)#.to('cuda')\n",
    "#model.load_state_dict(torch.load('baseline_noBN.pt'))\n",
    "#model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a04240",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_embed = np.load('possible_words_embed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043844d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6365463b",
   "metadata": {},
   "source": [
    "RL Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbeab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model trained from start\n",
    "# top = 0.5 does not work better\n",
    "# layers = 3, size = 64 about the same results\n",
    "# value += eps * best * np.random.randn() and eps=0.16/(i+1) and from trained model\n",
    "lr = 6e-5\n",
    "clip = 0.03\n",
    "epochs = 3\n",
    "damp = 1\n",
    "iterations = 50\n",
    "max_data = 2000\n",
    "states = set()\n",
    "opt = Adam(model.parameters(),betas=(0.85, 0.95),lr=lr)\n",
    "for i in range(iterations):\n",
    "    # policy evaluation\n",
    "    model.eval()\n",
    "    score = evaluate_save(matrix,np.arange(2309),policy_model,2309,0,model=model,words_embed=words_embed,top=0.6,\n",
    "                         eps=0.08/(i+1))\n",
    "    print('iter:{}, score:{}'.format(i,score))\n",
    "    \n",
    "    # prepare data for training\n",
    "    index,val,log_prob = zip(*out)\n",
    "    for element in index:\n",
    "        states.add(tuple(element))\n",
    "    print('set size:{}'.format(len(states)))\n",
    "    prob = np.array(log_prob)\n",
    "    prob -= prob.mean()\n",
    "    prob = np.exp(prob/damp)\n",
    "    prob = torch.tensor(prob,dtype=torch.float32,device='cuda')\n",
    "    length = torch.tensor([len(i) for i in index],dtype=torch.float32,device='cuda')\n",
    "    words = torch.tensor(words_embed[np.concatenate(index)]).long().to('cuda')\n",
    "    ys = torch.tensor(val,dtype=torch.float32,device='cuda')\n",
    "\n",
    "    \n",
    "    # policy update\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        yhat = model((words,length))\n",
    "        loss = torch.sum(prob*(ys-yhat)**2)/torch.sum(prob)\n",
    "        loss.backward()\n",
    "        print('loss:{}'.format(loss.item()))\n",
    "        clip_grad_value_(model.parameters(),clip)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    #print(model.w)\n",
    "    while len(out)>max_data:\n",
    "        out.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9a72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca16be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7d0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b6f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = -1\n",
    "for k,v in mapping.items():\n",
    "    if v>max_:\n",
    "        k_max = k\n",
    "        max_ = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea937ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1029411764705874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(matrix[:,np.array(k_max)],np.array(k_max),policy_lookup,len(k_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3534d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1029411764705874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9d45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f14a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1249999999999987"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly worse than # of steps required by mapping as expected\n",
    "evaluate(matrix[:,np.array(k_max)],np.array(k_max),policy_model,len(k_max),model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035a930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9693ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:0.0, steps:3.5275010827197937\n",
      "factor:0.5, steps:3.4638371589432673\n",
      "factor:1.0, steps:3.4634040710264204\n",
      "factor:1.5, steps:3.4634040710264204\n",
      "factor:2.0, steps:3.4634040710264204\n",
      "factor:2.5, steps:3.462970983109573\n",
      "factor:3.0, steps:3.4638371589432673\n",
      "factor:3.5, steps:3.4642702468601136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# entropy policy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy_entropy\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2309\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, steps:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i,steps))\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:100\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(matrix, index, policy, count, **kways)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m \u001b[38;5;66;03m# guess_row += p * 0\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     tmp2 \u001b[38;5;241m=\u001b[39m tmp \u001b[38;5;241m==\u001b[39m u\n\u001b[0;32m--> 100\u001b[0m     guess_row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m*\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m guess_row\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:86\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(matrix, index, policy, count, **kways)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# best = np.log2(count)\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkways\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m tmp \u001b[38;5;241m=\u001b[39m matrix[row]\n\u001b[1;32m     89\u001b[0m unq,counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(tmp,return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/LC/wordle/functions.py:165\u001b[0m, in \u001b[0;36mpolicy_entropy\u001b[0;34m(matrix, index, factor)\u001b[0m\n\u001b[1;32m    163\u001b[0m ps \u001b[38;5;241m=\u001b[39m counts\u001b[38;5;241m/\u001b[39mcount\n\u001b[1;32m    164\u001b[0m entro \u001b[38;5;241m=\u001b[39m entropy(ps)\n\u001b[0;32m--> 165\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43munq\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m242\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    167\u001b[0m     entro \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prob[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m factor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# entropy policy\n",
    "for i in np.linspace(0,7,15):\n",
    "    steps = evaluate(matrix,np.arange(2309),policy_entropy,2309,factor=i)\n",
    "    print('factor:{}, steps:{}'.format(i,steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56d63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1f55ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:1.0, steps:3.4634040710264204\n",
      "factor:1.25, steps:3.462970983109573\n",
      "factor:1.5, steps:3.4638371589432673\n",
      "factor:1.75, steps:3.4642702468601136\n",
      "factor:2.0, steps:3.4655695106106554\n"
     ]
    }
   ],
   "source": [
    "# entropy policy with depth info\n",
    "for i in np.linspace(1,2,5):\n",
    "    steps = evaluate_depth(matrix,np.arange(2309),policy_entropy_depth,2309,factor=i,depth=1)\n",
    "    print('factor:{}, steps:{}'.format(i,steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbe1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c17dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ba82ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5266349068860987"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how well model does on full problem that it is not trained on\n",
    "#     if count == 1: return 1\n",
    "#     if count == 2: return 1.5\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae855e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8778692074491117"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if entro == best:return row\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4707b1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6223473365093115"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                 if c == 1:\n",
    "#                     continue\n",
    "#                 if c == 2:\n",
    "#                     value += p\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4439de6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.558683412732789"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old policy_model\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b72109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7756604590731935"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new policy_model\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d52411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.873538328280638"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new + if entro==best: return row\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054ba07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5240363793850142"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new policy_model +\n",
    "#                 if c == 1:\n",
    "#                     continue\n",
    "#                 if c == 2:\n",
    "#                     value += p\n",
    "evaluate(matrix,np.arange(2309),policy_model,2309,model=model,words_embed=words_embed,top=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2917428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b658f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6bc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0954569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
